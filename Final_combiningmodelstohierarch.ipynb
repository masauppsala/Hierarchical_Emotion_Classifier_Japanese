{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmJlpXNUoN_1"
      },
      "outputs": [],
      "source": [
        "! pip install fugashi ipadic # Japanese language processing libraries\n",
        "! pip install -U accelerate # Hugging Face's Accelerate library for mixed precision and distributed training\n",
        "! pip install -U transformers # Hugging Face's library for pretrained models\n",
        "! pip install datasets # Library for managing datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "JCrTJy9gM8sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktE6qjyu4k_O"
      },
      "outputs": [],
      "source": [
        "! wget https://github.com/ids-cv/wrime/raw/master/wrime-ver2.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GGKsGC_4q7h"
      },
      "outputs": [],
      "source": [
        "df_wrime = pd.read_table('wrime-ver2.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the max emotion intensity for a row\n",
        "def max_emotion_intensity(row):\n",
        "    avg_readers_emotions = {emotion: row[emotion] for emotion in row.index if emotion.startswith('Avg. Readers_') and emotion != 'Avg. Readers_Sentiment'}\n",
        "    max_intensity = max(avg_readers_emotions.values())\n",
        "    return max_intensity\n",
        "\n",
        "# Apply the function to each row to get the max emotion intensity\n",
        "df_wrime['Max_Emotion_Intensity'] = df_wrime.apply(max_emotion_intensity, axis=1)\n",
        "\n",
        "# Filter out rows where the max emotion intensity is 0\n",
        "df_wrime = df_wrime[df_wrime['Max_Emotion_Intensity'] > 0]"
      ],
      "metadata": {
        "id": "OwxRnU33MxPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RxXJB2oDXrN"
      },
      "outputs": [],
      "source": [
        "# Define the sentiment scores for each emotion\n",
        "emotion_sentiment_scores = {\n",
        "    \"Joy\": 1.117353,\n",
        "    \"Sadness\": -1.029128,\n",
        "    \"Anticipation\": 0.653459,\n",
        "    \"Surprise\": 0.050611,\n",
        "    \"Anger\": -1.365032,\n",
        "    \"Fear\": -0.892089,\n",
        "    \"Disgust\": -1.148589,\n",
        "    \"Trust\": 1.197159\n",
        "}\n",
        "\n",
        "def adjust_primary_emotion_intensity_for_ties(row):\n",
        "    # Extract only the Avg. Readers_ emotions and their scores, excluding Avg. Readers_Sentiment\n",
        "    avg_readers_emotions = {emotion: row[emotion] for emotion in row.index if emotion.startswith('Avg. Readers_') and emotion != 'Avg. Readers_Sentiment'}\n",
        "\n",
        "    # Find the maximum intensity among the Avg. Readers_ emotions\n",
        "    max_intensity = max(avg_readers_emotions.values())\n",
        "    # Count how many emotions share this maximum intensity\n",
        "    emotions_with_max_intensity = [emotion for emotion, intensity in avg_readers_emotions.items() if intensity == max_intensity]\n",
        "\n",
        "    # Proceed only if there's a tie for the maximum intensity\n",
        "    if len(emotions_with_max_intensity) > 1:\n",
        "        avg_readers_sentiment = row['Avg. Readers_Sentiment']\n",
        "\n",
        "        # Find the emotion (from those with max intensity) whose sentiment score is closest to the Avg. Readers_Sentiment\n",
        "        closest_emotion = min(emotions_with_max_intensity, key=lambda x: abs(emotion_sentiment_scores[x.replace('Avg. Readers_', '')] - avg_readers_sentiment))\n",
        "\n",
        "        # Adjust the intensity of the closest emotion by adding an insignificant number (0.01)\n",
        "        row[closest_emotion] += 0.01\n",
        "        row['Max_Emotion_Intensity'] = max_intensity + 0.01\n",
        "\n",
        "    return row\n",
        "\n",
        "# Apply the adjustment function to each row\n",
        "df_wrime = df_wrime.apply(adjust_primary_emotion_intensity_for_ties, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to determine the primary emotion for each row\n",
        "def determine_primary_emotion(row):\n",
        "    # Extract only the Avg. Readers_ emotions and their scores, excluding Avg. Readers_Sentiment\n",
        "    avg_readers_emotions = {emotion: row[emotion] for emotion in row.index if emotion.startswith('Avg. Readers_') and emotion != 'Avg. Readers_Sentiment'}\n",
        "\n",
        "    # Find the emotion with the highest intensity\n",
        "    primary_emotion = max(avg_readers_emotions, key=avg_readers_emotions.get)\n",
        "    return primary_emotion.replace('Avg. Readers_', '')\n",
        "\n",
        "# Apply the function to each row to identify the primary emotion\n",
        "df_wrime['Primary_Emotion'] = df_wrime.apply(determine_primary_emotion, axis=1)\n",
        "\n",
        "print(df_wrime['Primary_Emotion'].value_counts())"
      ],
      "metadata": {
        "id": "aOVUufbdNK9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VId95GkdE6pz"
      },
      "outputs": [],
      "source": [
        "# Splitting the DataFrame into train, validation, and test sets\n",
        "# First, split into train+dev and test\n",
        "train_dev_df, df_test = train_test_split(df_wrime, test_size=0.2, random_state=42)\n",
        "# Then, split train+dev into actual train and dev\n",
        "df_train, df_dev = train_test_split(train_dev_df, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vf3Msus1h5q"
      },
      "outputs": [],
      "source": [
        "#Creat easy dataset\n",
        "# List of emotion columns to check\n",
        "emotion_columns = [\n",
        "    'Avg. Readers_Joy', 'Avg. Readers_Sadness', 'Avg. Readers_Anticipation',\n",
        "    'Avg. Readers_Surprise', 'Avg. Readers_Anger', 'Avg. Readers_Fear',\n",
        "    'Avg. Readers_Disgust', 'Avg. Readers_Trust'\n",
        "]\n",
        "\n",
        "# Values to remove\n",
        "values_to_remove = [1.01, 2.01, 3.01]\n",
        "# Remove rows where any of the emotion columns have values in values_to_remove to creat easy dataset\n",
        "easy_df_train = df_train[~df_train[emotion_columns].apply(lambda x: x.isin(values_to_remove).any(), axis=1)]\n",
        "easy_df_dev = df_dev[~df_dev[emotion_columns].apply(lambda x: x.isin(values_to_remove).any(), axis=1)]\n",
        "easy_df_test = df_test[~df_test[emotion_columns].apply(lambda x: x.isin(values_to_remove).any(), axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmjiaxQzGE3R"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9vYdX0-rOnW"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNzQhbFAnK_z"
      },
      "outputs": [],
      "source": [
        "#Load list models\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "neutral_emotional_classifier = AutoModelForSequenceClassification.from_pretrained('experiarms777/Neutral_Emotional_Classifier')\n",
        "\n",
        "positive_negative_classifier = AutoModelForSequenceClassification.from_pretrained('experiarms777/Positive_Negative_Japanese_Classifier')\n",
        "\n",
        "eight_emotions_classifier = AutoModelForSequenceClassification.from_pretrained('experiarms777/Eight_Emotions_Japanese_Classifier')\n",
        "\n",
        "surprise_otheremotions_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Surprise_Detection_Japanese\")\n",
        "\n",
        "negative_emotions_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Negative_Emotions_Classifier_Japanese\")\n",
        "\n",
        "positive_emotions_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Positive_Emotions_Classifier_Japanese\")\n",
        "\n",
        "positive_verypositive_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Positive_Very_Positive_Classifier_Japanese\")\n",
        "\n",
        "negative_verynegative_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Negative_Very_Negative_Classifier_Japanese\")\n",
        "\n",
        "joy_trust_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Joy_Trust_Classifier_Japanese\")\n",
        "\n",
        "anger_disgust_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Anger_Disgust_Classifier_Japanese\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load single label models\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "neutral_emotional_classifier = AutoModelForSequenceClassification.from_pretrained('experiarms777/Neutral_Emotional_Classifier')\n",
        "\n",
        "positive_negative_classifier = AutoModelForSequenceClassification.from_pretrained('experiarms777/Positive_Negative_Japanese_Classifier')\n",
        "\n",
        "eight_emotions_classifier = AutoModelForSequenceClassification.from_pretrained('experiarms777/Single_Label_Eight_Emotions_Classifier_Japanese')\n",
        "\n",
        "surprise_otheremotions_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Surprise_Detection_Japanese\")\n",
        "\n",
        "negative_emotions_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Single_Label_Negative_Emotions_Classifier_Japanese\")\n",
        "\n",
        "positive_emotions_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Single_Label_Positive_Emotions_Classifier_Japanese\")\n",
        "\n",
        "positive_verypositive_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Positive_Very_Positive_Classifier_Japanese\")\n",
        "\n",
        "negative_verynegative_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Negative_Very_Negative_Classifier_Japanese\")\n",
        "\n",
        "joy_trust_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Single_Label_Joy_Trust_Classifier_Japanese\")\n",
        "\n",
        "anger_disgust_classifier = AutoModelForSequenceClassification.from_pretrained(\"experiarms777/Single_Label_Anger_Disgust_Classifier_Japanese\")"
      ],
      "metadata": {
        "id": "ncmY-WKhRHfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD4pS__OraBU"
      },
      "outputs": [],
      "source": [
        "neutral_emotional_classifier = neutral_emotional_classifier.to(device)\n",
        "positive_negative_classifier = positive_negative_classifier.to(device)\n",
        "eight_emotions_classifier = eight_emotions_classifier.to(device)\n",
        "surprise_otheremotions_classifier = surprise_otheremotions_classifier.to(device)\n",
        "negative_emotions_classifier = negative_emotions_classifier.to(device)\n",
        "positive_emotions_classifier = positive_emotions_classifier.to(device)\n",
        "positive_verypositive_classifier = positive_verypositive_classifier.to(device)\n",
        "negative_verynegative_classifier = negative_verynegative_classifier.to(device)\n",
        "joy_trust_classifier = joy_trust_classifier.to(device)\n",
        "anger_disgust_classifier = anger_disgust_classifier.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1Gzotb15-Hr"
      },
      "outputs": [],
      "source": [
        "def classify_neutral_postivenegative(inputs, threshold):\n",
        "    # neutral_emotional_classifier is trained to classify between Neutral and Positive/Negative\n",
        "    with torch.no_grad():\n",
        "        outputs = neutral_emotional_classifier(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    # Classify as \"Positive or Negative\" if the probability exceeds the threshold\n",
        "    # probabilities[1] corresponds to the \"Positive/Negative\" class\n",
        "    if probabilities[1] > threshold:\n",
        "        return \"Positive or Negative\"\n",
        "    else:\n",
        "        return \"Neutral\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVWmTo_YbUX2"
      },
      "outputs": [],
      "source": [
        "def classify_eight_emotions(inputs, threshold = 0.4):\n",
        "    # eight_emotions_classifier is trained to classify between all the eight emotions\n",
        "    with torch.no_grad():\n",
        "        outputs = eight_emotions_classifier(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    # probabilities[7] corresponds to the \"Trust\" class\n",
        "    if probabilities[7] > threshold:\n",
        "        return \"Trust\"\n",
        "    # Process the model output (e.g., extract the predicted class)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "    labels = [ 'Joy', 'Sadness', 'Anticipation', 'Surprise', 'Anger', 'Fear', 'Disgust', 'Trust']\n",
        "    predicted_label = labels[predictions.item()]\n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzxMf6rJH5b3"
      },
      "outputs": [],
      "source": [
        "def classify_positive_negative(inputs, threshold):\n",
        "    # positive_negative_classifier is trained to classify between Postive and Negative\n",
        "    with torch.no_grad():\n",
        "        outputs = positive_negative_classifier(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    # probabilities[1] corresponds to the \"Positive\" class and probabilities[0] corresponds to the \"Negative\"\n",
        "    if probabilities[1] > threshold:\n",
        "        return \"Positive\"\n",
        "    elif probabilities[0] > threshold:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "      return \"Neutral\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubp3NruHu-e0"
      },
      "outputs": [],
      "source": [
        "def classify_surprise_other(inputs, threshold):\n",
        "    # surprise_otheremotions_classifier is trained to classify between Surprise and Other Emotions\n",
        "    with torch.no_grad():\n",
        "        outputs = surprise_otheremotions_classifier(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    # Classify as \"Surprise\" if the probability exceeds the threshold\n",
        "    # Assumes probabilities[1] corresponds to the \"Surprise\" class\n",
        "    if probabilities[1] > threshold:\n",
        "        return \"Surprise\"\n",
        "    else:\n",
        "      return \"Other Emotions\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "396YflLT5PQI"
      },
      "outputs": [],
      "source": [
        "def classify_Joy_Trust(inputs, threshold):\n",
        "    # joy_trust_classifier is trained to classify between Joy and Trust\n",
        "    with torch.no_grad():\n",
        "        outputs = joy_trust_classifier(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    # Classify as \"Joy\" if the probability exceeds the threshold\n",
        "    if probabilities[0] > threshold:\n",
        "        return \"Joy\"\n",
        "    else:\n",
        "      return \"Trust\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U26F-SdN7S0h"
      },
      "outputs": [],
      "source": [
        "def classify_Anger_Disgust(inputs, threshold):\n",
        "    # anger_disgust_classifier is trained to classify between Anger and Disgust\n",
        "    with torch.no_grad():\n",
        "        outputs = anger_disgust_classifier(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    # Classify as \"Disgust\" if the probability exceeds the threshold\n",
        "    if probabilities[1] > threshold:\n",
        "        return \"Disgust\"\n",
        "    else:\n",
        "      return \"Anger\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNNk8Nq4aPCc"
      },
      "outputs": [],
      "source": [
        "def classify_positive_verypositive(inputs):\n",
        "    with torch.no_grad():\n",
        "        # Predict with the model\n",
        "        outputs = positive_verypositive_classifier(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    # Extract the very positive probability\n",
        "    very_positive_probability = probabilities[1]\n",
        "    return very_positive_probability\n",
        "\n",
        "def adjust_probabilities_with_positivity(probabilities, inputs):\n",
        "    \"\"\"\n",
        "    Adjust probabilities based on the positivity score and the inherent sentiment score of each emotion.\n",
        "    \"\"\"\n",
        "    positivity_score = classify_positive_verypositive(inputs)\n",
        "    adjusted_probabilities = []\n",
        "    sentiment_scores = [1.117353, 0.653459, 1.197159]  # Joy, Anticipation, Trust sentiment scores\n",
        "    max_sentiment_score = max(sentiment_scores)\n",
        "\n",
        "    for prob, sentiment_score in zip(probabilities, sentiment_scores):\n",
        "        adjustment_factor = 1 + (sentiment_score / max_sentiment_score) * positivity_score\n",
        "        adjusted_prob = prob * adjustment_factor\n",
        "        adjusted_probabilities.append(adjusted_prob)\n",
        "\n",
        "    total = sum(adjusted_probabilities)\n",
        "    normalized_probabilities = [prob / total for prob in adjusted_probabilities]\n",
        "\n",
        "    return normalized_probabilities\n",
        "\n",
        "def classify_positive_emotions(inputs, threshold = 0.4):\n",
        "    with torch.no_grad():\n",
        "        outputs = positive_emotions_classifier(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    adjusted_probabilities = adjust_probabilities_with_positivity(probabilities, inputs)\n",
        "    predictions = torch.argmax(torch.tensor(adjusted_probabilities), dim=-1)\n",
        "    labels = ['Joy', 'Anticipation', 'Trust']\n",
        "    if adjusted_probabilities[2] > threshold:\n",
        "        return \"Trust\"\n",
        "    predicted_label = labels[predictions.item()]\n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDkSIs0BiXEI"
      },
      "outputs": [],
      "source": [
        "def classify_negative_verynegative(inputs):\n",
        "    with torch.no_grad():\n",
        "        # Predict with the model\n",
        "        outputs = negative_verynegative_classifier(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    # Extract the very positive probability\n",
        "    very_negative_probability = probabilities[1]\n",
        "    return very_negative_probability\n",
        "\n",
        "def adjust_probabilities_with_negativity(probabilities, inputs):\n",
        "    \"\"\"\n",
        "    Adjust probabilities based on the negativity score and the inherent sentiment score of each emotion.\n",
        "    \"\"\"\n",
        "    negativity_score = classify_negative_verynegative(inputs)\n",
        "    adjusted_probabilities = []\n",
        "    sentiment_scores = [-1.029128, -1.365032, -0.892089, -1.148589] #'Avg. Readers_Sadness','Avg. Readers_Anger', 'Avg. Readers_Fear', 'Avg. Readers_Disgust'\n",
        "    max_sentiment_score = min(sentiment_scores)\n",
        "\n",
        "    for prob, sentiment_score in zip(probabilities, sentiment_scores):\n",
        "        adjustment_factor = 1 + (sentiment_score / max_sentiment_score) * negativity_score\n",
        "        adjusted_prob = prob * adjustment_factor\n",
        "        adjusted_probabilities.append(adjusted_prob)\n",
        "\n",
        "    total = sum(adjusted_probabilities)\n",
        "    normalized_probabilities = [prob / total for prob in adjusted_probabilities]\n",
        "\n",
        "    return normalized_probabilities\n",
        "\n",
        "def classify_negative_emotions(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = negative_emotions_classifier(**inputs)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().tolist()\n",
        "    adjusted_probabilities = adjust_probabilities_with_negativity(probabilities, inputs)\n",
        "    predictions = torch.argmax(torch.tensor(adjusted_probabilities), dim=-1)\n",
        "    labels = ['Sadness','Anger', 'Fear', 'Disgust']\n",
        "    predicted_label = labels[predictions.item()]\n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jawvoC8tT_zC"
      },
      "outputs": [],
      "source": [
        "def predict_primary_emotion(text, thresholds_neutral_positive_negative, thresholds_positive_negative, thresholds_surprise_other):\n",
        "    # Neutral vs. Positive/Negative\n",
        "    sentiment = classify_neutral_postivenegative(text, thresholds_neutral_positive_negative) # Neutral or Positive・Negative\n",
        "    if sentiment == \"Neutral\":\n",
        "        # Handle Neutral-specific classifications\n",
        "        if classify_surprise_other(text, thresholds_surprise_other) == 'Surprise':\n",
        "          return 'Surprise'\n",
        "        else:\n",
        "          predicted_emotion = classify_eight_emotions(text)\n",
        "          return predicted_emotion\n",
        "\n",
        "    elif sentiment == \"Positive or Negative\":\n",
        "        # Classify Positive/Negative texts\n",
        "        if classify_positive_negative(text, thresholds_positive_negative) == 'Positive':\n",
        "          positive_emotion = classify_positive_emotions(text)\n",
        "          return positive_emotion\n",
        "        elif classify_positive_negative(text, thresholds_positive_negative) == 'Negative':\n",
        "          negative_emotion = classify_negative_emotions(text)\n",
        "          return negative_emotion\n",
        "        else:\n",
        "          if classify_surprise_other(text, thresholds_surprise_other) == 'Surprise':\n",
        "            return 'Surprise'\n",
        "          else:\n",
        "            predicted_emotion = classify_eight_emotions(text)\n",
        "            return predicted_emotion\n",
        "\n",
        "def main(text, thresholds_neutral_positive_negative, thresholds_positive_negative, thresholds_surprise_other, thresholds_Joy_Trust, thresholds_Anger_Disgust):\n",
        "    # Implement model loading, text preprocessing, and classification\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    primary_emotion = predict_primary_emotion(inputs, thresholds_neutral_positive_negative, thresholds_positive_negative, thresholds_surprise_other)\n",
        "    if primary_emotion == 'Joy':\n",
        "      predicted_emotion = classify_Joy_Trust(inputs,thresholds_Joy_Trust)\n",
        "      return predicted_emotion\n",
        "    elif primary_emotion == 'Disgust':\n",
        "      predicted_emotion = classify_Anger_Disgust(inputs, thresholds_Anger_Disgust)\n",
        "      return predicted_emotion\n",
        "    else:\n",
        "      return primary_emotion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmIZbtgGmlTH"
      },
      "outputs": [],
      "source": [
        "threshold_npn = 0.9\n",
        "threshold_pn = 0.9\n",
        "threshold_so = 0.9\n",
        "threshold_ad = 0.4\n",
        "threshold_jt = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zmlx1ZVZM_k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "predicted_emotions = df_test['Sentence'].apply(lambda x: main(x, threshold_npn, threshold_pn, threshold_so, threshold_ad, threshold_jt))\n",
        "\n",
        "# True labels\n",
        "true_emotions = df_test['Primary_Emotion']\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_emotions, predicted_emotions)\n",
        "precision = precision_score(true_emotions, predicted_emotions, average='macro', zero_division=0)\n",
        "recall = recall_score(true_emotions, predicted_emotions, average='macro', zero_division=0)\n",
        "f1 = f1_score(true_emotions, predicted_emotions, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# For a detailed classification report\n",
        "print(classification_report(true_emotions, predicted_emotions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Eg4uCx4y8sT"
      },
      "outputs": [],
      "source": [
        "# Add the predictions to the DataFrame\n",
        "df_test['Predicted_Emotion'] = predicted_emotions\n",
        "\n",
        "# Filter for rows where the prediction does not match the true label\n",
        "incorrect_predictions = df_test[df_test['Primary_Emotion'] != df_test['Predicted_Emotion']]\n",
        "\n",
        "# Display the sentences with incorrect predictions along with their true and predicted labels\n",
        "incorrect_predictions[['Sentence', 'Primary_Emotion', 'Predicted_Emotion']].to_csv('listalonelincorrect_predictions.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY-XcNep_IXk"
      },
      "outputs": [],
      "source": [
        "thresholds_neutral_positive_negative = [0.9]\n",
        "thresholds_positive_negative = [0.9]\n",
        "thresholds_surprise_other = [0.9]\n",
        "thresholds_Anger_Disgust = [0.4]\n",
        "thresholds_Joy_Trust = [0.3, 0.4, 0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oanmKmTb4l59"
      },
      "outputs": [],
      "source": [
        "#Grid search for thresholds\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "best_f1 = 0\n",
        "best_thresholds = (0, 0, 0, 0, 0)\n",
        "\n",
        "for threshold_npn in thresholds_neutral_positive_negative:\n",
        "  for threshold_pn in thresholds_positive_negative:\n",
        "    for threshold_so in thresholds_surprise_other:\n",
        "       for threshold_ad in thresholds_Anger_Disgust:\n",
        "        for threshold_jt in thresholds_Joy_Trust:\n",
        "          current_accuracy, precision, recall, f1 = evaluate_model_with_thresholds(df_dev, threshold_npn, threshold_pn, threshold_so, threshold_ad, threshold_jt)\n",
        "          print(f\"Accuracy with NPN={threshold_npn} and PN={threshold_pn} and SO={threshold_so} and AD={threshold_ad} and JT={threshold_jt}: {current_accuracy} {precision} {recall} {f1}\")\n",
        "\n",
        "          if f1 > best_f1:\n",
        "              best_f1 = f1\n",
        "              best_thresholds = (threshold_npn, threshold_pn, threshold_so, threshold_ad, threshold_jt)\n",
        "\n",
        "print(f\"Best thresholds: NPN={best_thresholds[0]}, PN={best_thresholds[1]}, SO={best_thresholds[2]}, AD={best_thresholds[3]}, JT={best_thresholds[4]} with accuracy: {best_f1}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}